<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="Content-Type" content="text/html" />
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- <meta
            http-equiv="Content-Security-Policy"
            content="default-src *" /> -->

        <!-- Icon start -->
        <link rel="icon" href="../images/icons/IconSheet.svg#browserlogo">
        <link rel="apple-touch-icon" href="../images/icons/IconSheet.svg#browserlogo">
        <link rel="shortcut icon" href="../images/icons/IconSheet.svg#browserlogo" />
        <link rel="mask-icon" href="../images/icons/IconSheet.svg#browserlogo" />
        <!-- Icon end -->

        <!-- Global site tag (gtag.js) - Google Analytics START ------------------->

        <script defer src="https://www.googletagmanager.com/gtag/js?id=G-2W1VXE5GSE"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-2W1VXE5GSE');
        </script>
        
        <!-- Global site tag (gtag.js) - Google Analytics END ---------------------->

        <!-- NO JS Behavior START -->
        <noscript>
            <style>
                nav.sidenav {display:none;}
                li.nav-item{display:none;}
            </style>
        </noscript>
         <!-- NO JS Behavior END -->

        <title>Jason Yang - Intro To Statistical Learning Notes</title>
        <link rel="stylesheet" type="text/css" href="../css/default.css" />
    </head>

    <body>
        <!-- Side navigation start -->
        <nav class="sidenav">
            <li class="logo">
                <a href="#" class="nav-link">
                    <span class="link-text logo-text">Jason</span>
                    <svg><use href="../images/icons/IconSheet.svg#sidebardod"></use></svg>
                </a>
            </li>
        
            
            <li class="nav-item">
                <a href="../tags/mathcs.html" class="nav-link">
                    <svg><use href="../images/icons/IconSheet.svg#lambda"></use></svg>
                    <span class="link-text">Math/CS</span>
                </a>
            </li>
                
            <li class="nav-item">
                <a href="../tags/prog.html" class="nav-link">
                    <svg><use href="../images/icons/IconSheet.svg#progcode"></use></svg>
                    <span class="link-text">Prog</span>
                </a>
            </li>


            <li class="nav-item">
                <a href="../tags/AI.html" class="nav-link">
                    <svg><use href="../images/icons/IconSheet.svg#AIbrain"></use></svg>
                    <span class="link-text">ML/AI</span>
                </a>
            </li>

            <li class="nav-item">
                <a href="../tags/tech.html" class="nav-link">
                    <svg><use href="../images/icons/IconSheet.svg#hardware"></use></svg>
                    <span class="link-text">Tech</span>
                </a>
            </li>

            <li class="nav-item">
                <a href="../tags/musings.html" class="nav-link">
                    <svg><use href="../images/icons/IconSheet.svg#thinker"></use></svg>
                    <span class="link-text">Musings</span>
                </a>
            </li>


            <li class="nav-item">
                <a href="https://github.com/lambdaJasonYang" class="nav-link">
                    <svg><use href="../images/icons/IconSheet.svg#github"></use></svg>
                    <span class="link-text">Github</span>
                </a>
            </li>
        </nav>
        <!-- Side navigation end -->
        <div id="header">
            <div id="logo">
                <a href="../">Jason Yang</a>
            </div>
            <div id="navigation">
                <a href="../">Home</a>
                <a href="../about.html">About</a>
                <a href="../contact.html">Contact</a>
                <a href="../archive.html">Archive</a>
            </div>
        </div>

        <div id="content">
            <h1>Intro To Statistical Learning Notes</h1>
            

            <div class="info">
    Posted on April  2, 2019
    
</div>
<div class="info">
    
    Tags: <a title="All pages tagged 'mathcs'." href="../tags/mathcs.html">mathcs</a>, <a title="All pages tagged 'appliedmath'." href="../tags/appliedmath.html">appliedmath</a>, <a title="All pages tagged 'AI'." href="../tags/AI.html">AI</a>, <a title="All pages tagged 'stats'." href="../tags/stats.html">stats</a>, <a title="All pages tagged 'notes'." href="../tags/notes.html">notes</a>
    
</div>
<div id="TOC"><ul>
<li><a href="#terms"><span class="toc-section-number">1</span> terms</a>
<ul>
<li><a href="#variance"><span class="toc-section-number">1.1</span> Variance</a></li>
</ul></li>
<li><a href="#chapter-2-ols"><span class="toc-section-number">2</span> Chapter 2 OLS</a>
<ul>
<li><a href="#reality-vs-estimate"><span class="toc-section-number">2.1</span> Reality vs Estimate</a></li>
<li><a href="#residual-vs-irreducible-error"><span class="toc-section-number">2.2</span> Residual vs Irreducible Error</a></li>
<li><a href="#finding-best-fit"><span class="toc-section-number">2.3</span> Finding best fit</a>
<ul>
<li><a href="#rss-residual-sum-squared"><span class="toc-section-number">2.3.1</span> RSS: Residual Sum Squared</a></li>
<li><a href="#covariance-matrix"><span class="toc-section-number">2.3.2</span> Covariance matrix</a></li>
</ul></li>
<li><a href="#validate-linearity"><span class="toc-section-number">2.4</span> Validate linearity</a>
<ul>
<li><a href="#t-test"><span class="toc-section-number">2.4.1</span> T-test</a></li>
<li><a href="#validate-multi-linear-regression-model"><span class="toc-section-number">2.4.2</span> Validate multi-linear regression model</a></li>
</ul></li>
<li><a href="#model-fit-loss-function"><span class="toc-section-number">2.5</span> Model fit ( Loss Function )</a>
<ul>
<li><a href="#mse"><span class="toc-section-number">2.5.1</span> MSE</a></li>
<li><a href="#r2"><span class="toc-section-number">2.5.2</span> R^2</a></li>
<li><a href="#cor"><span class="toc-section-number">2.5.3</span> Cor</a></li>
</ul></li>
<li><a href="#prediction"><span class="toc-section-number">2.6</span> Prediction</a></li>
</ul></li>
<li><a href="#chapter-4-classification"><span class="toc-section-number">3</span> Chapter 4 Classification</a></li>
<li><a href="#chapter-5-resampling"><span class="toc-section-number">4</span> Chapter 5 Resampling</a></li>
</ul></div>
<p><code class="sourceCode r">Wage</code> : Linear Regression
How does <code class="sourceCode r">age</code> affect <code class="sourceCode r">wage</code></p>
<p><code class="sourceCode r">Smarket</code> : Classification
Classification</p>
<section id="terms" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> terms</h1>
<section id="variance" class="level2" data-number="1.1">
<h2 data-number="1.1"><span class="header-section-number">1.1</span> Variance</h2>
<p>variance is squared(distance-to-mean)<br />
That means there is larger value for scattered points than clumped points.<br />
The square operation has an absolute value like effect.</p>
<p>TSS = Total sum squared = sum of variance of y’s</p>
<p>Normalising against variance by dividing by TSS.</p>
</section>
</section>
<section id="chapter-2-ols" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Chapter 2 OLS</h1>
<p>Goal: Find <span class="math inline">\(\beta\)</span> weight vector that minimizes sum square residual</p>
<p>Method:
1. Find inflection(min/max): Solve derivative of Error wrt. weight equal to 0
2. Prove that this is a min, not a max: Check 2nd derivative is positive definite(analogous to postive in real numbers)</p>
<section id="reality-vs-estimate" class="level2" data-number="2.1">
<h2 data-number="2.1"><span class="header-section-number">2.1</span> Reality vs Estimate</h2>
<p>Ideal Model of Reality
<span class="math display">\[Y = X\beta + \epsilon\]</span></p>
<p>Estimated Model
<span class="math display">\[Y=X\hat{\beta} + e\]</span></p>
<ul>
<li>Population analogous to Reality</li>
<li>Sample analogous to a simulation or model of reality</li>
</ul>
<p>Statistics is about using Samples(Simulation/Models/Estimations) to estimate Population(Reality)</p>
</section>
<section id="residual-vs-irreducible-error" class="level2" data-number="2.2">
<h2 data-number="2.2"><span class="header-section-number">2.2</span> Residual vs Irreducible Error</h2>
<p><span class="math display">\[X_1 .. X_n \sim N(\mu ,\sigma^2)\]</span>
<span class="math inline">\(X_1..X_n\)</span> each represent the choice of a random singleton subset AKA singleton sample from population.<br />
<span class="math inline">\(\mu\)</span> is the population mean.</p>
<p><span class="math display">\[\bar{X} = \frac{X_1 + .. X_n}{n}\]</span>
<span class="math inline">\(\bar{X}\)</span> is sample mean. Notice it is a random variable because our choice of sample subset is random which also implies a random meam for each of these possible subsets.</p>
<p><span class="math display">\[\bar{X} \sim N(\mu, \sigma^2)\]</span></p>
<p><span class="math display">\[E(Y_i) = \mu\]</span>
<span class="math display">\[\epsilon_i = Y_i - E(Y_i) \text{ typically impossible to find}\]</span></p>
<p><span class="math display">\[ e_i = X_i - \bar{X}\]</span></p>
<p><span class="math display">\[e \neq \epsilon\]</span></p>
<p>Residuals <span class="math inline">\(e\)</span> are basically estimates of Error <span class="math inline">\(\epsilon\)</span></p>
<ul>
<li><span class="math inline">\(\epsilon\)</span> is random noise of reality we typically can’t measure.
<ul>
<li>Error is random error from population data.<br />
</li>
</ul></li>
<li><span class="math inline">\(e\)</span> is our residual error: vertical distance of datapoint from best-fit line
<ul>
<li>Residual is deviation between our estimated model and sample data.</li>
</ul></li>
</ul>
<blockquote>
<p>We can <strong>ignore our Ideal Model</strong> <span class="math inline">\(\dot{Y},\dot{\beta},\epsilon\)</span> because they are simply model of an impossible ideal.</p>
</blockquote>
</section>
<section id="finding-best-fit" class="level2" data-number="2.3">
<h2 data-number="2.3"><span class="header-section-number">2.3</span> Finding best fit</h2>
<p>Regression is the best fit line that is minimizes <span class="math inline">\(e\)</span> or residual squared error.</p>
<p><span class="math display">\[Y=X\hat{\beta} + e\]</span></p>
<p><span class="math display">\[e=Y-X\hat{\beta}\]</span></p>
<section id="rss-residual-sum-squared" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1"><span class="header-section-number">2.3.1</span> RSS: Residual Sum Squared</h3>
<p>Sum of Squared residuals</p>
<p><span class="math display">\[RSS(\hat{\beta}) = e^t e \]</span></p>
<p><span class="math display">\[e^Te = (Y-X\hat{\beta})^T(Y-X\hat{\beta})\]</span></p>
<p>Set derivative to 0 to find inflection point</p>
<p><span class="math display">\[\frac{\partial e^Te}{\partial\beta}=-2X^TY+2X^TX\hat{\beta} = 0\]</span></p>
<p><span class="math display">\[(X^TX)\hat{\beta}=X^T Y\]</span></p>
<p><span class="math display">\[ \hat{Y} = X\hat{\beta}=(X^T X)^{-1} X^T Y\]</span></p>
<p><span class="math display">\[\hat{Y} = (X^T X)^{-1} X^T ( X \beta + \epsilon )\]</span></p>
<p>Show that this inflection point is minimum by proving the 2nd derivative is positive (or positive definite for matrices).</p>
<p><span class="math display">\[\frac{\partial^2 e^Te}{\partial\beta \partial\beta^T} = 2X^T X\]</span><br />
Assuming X has full column rank, <span class="math inline">\(X^T X\)</span> can be shown to be positive definite.</p>
<section id="axb" class="level4" data-number="2.3.1.1">
<h4 data-number="2.3.1.1"><span class="header-section-number">2.3.1.1</span> Ax=b</h4>
<p>Tricky</p>
<ul>
<li><span class="math inline">\(X\beta = Y\)</span></li>
<li><span class="math inline">\(Ax = b\)</span></li>
</ul>
<p>The <span class="math inline">\(\beta\)</span> represents <span class="math inline">\(x\)</span>.<br />
The input <span class="math inline">\(X\)</span> does NOT represent <span class="math inline">\(x\)</span></p>
<p>Each input or row of <span class="math inline">\(X\)</span> represent an equation or constraint which constrains the beta coefficients.<br />
This is an overdetermined system (too many constraints/equation against too few variables)<br />
Overdetermined systems have no exact solutions but we can find the best fit solution or <span class="math inline">\(x\)</span>(in our case coefficient <span class="math inline">\(\beta\)</span>)</p>
</section>
</section>
<section id="covariance-matrix" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2"><span class="header-section-number">2.3.2</span> Covariance matrix</h3>
<p>The <span class="math inline">\(X^T X\)</span> is the Covariance Matrix in multivariate normal distribution.</p>
<p>$$= Cov(X,X) = (X_i - _i)(X_j-_j)</p>
<p><span class="math display">\[ E[Y-\hat{Y}]^2 = E[f(X)+\epsilon -\hat{f}(X)]^2 = {\color{red}E[f(X)-\hat{f}(X)]^2} + Var(\epsilon)\]</span></p>
<p><span class="math display">\[{\color{red}e = f(X)-\hat{f}(X)}\]</span></p>
<ul>
<li>reducible error : <span class="math inline">\({\color{red}E[f(X)-\hat{f}(X)]^2}\)</span></li>
<li>irreducible error: <span class="math inline">\(Var(\epsilon)\)</span></li>
</ul>
<p>Steps:</p>
<ol type="1">
<li>Choose model: Linear equation</li>
</ol>
<p><span class="math display">\[ Y = f(X_1,X_2,...) + \epsilon\]</span></p>
<p><span class="math inline">\(f\)</span> is matrix multiplication with weight vector <span class="math inline">\(\beta\)</span></p>
<p><span class="math display">\[Y = X\beta + \epsilon\]</span></p>
<ol start="2" type="1">
<li>Train parameters: Ordinary Least Squares(OLS)</li>
</ol>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">6</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">50</span>,<span class="at">mean =</span> <span class="dv">0</span>,<span class="at">sd =</span> <span class="dv">1</span>)  <span class="co"># creates 50 points</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>,<span class="at">mean=</span><span class="dv">1</span>,<span class="at">sd=</span><span class="fl">0.5</span>) <span class="co"># creates 50 points </span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(x,y) <span class="co"># correlation</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.8344</span></span></code></pre></div>
</section>
</section>
<section id="validate-linearity" class="level2" data-number="2.4">
<h2 data-number="2.4"><span class="header-section-number">2.4</span> Validate linearity</h2>
<ul>
<li>We can use linear regression on any dataset but that DOES NOT imply a linear relation exists.<br />
</li>
<li>We must perform t-test(single independent var) or ANOVA F-test(multiple independent var) on the linear regression model’s coefficients to prove whether a linear relation exists.</li>
</ul>
<section id="t-test" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1"><span class="header-section-number">2.4.1</span> T-test</h3>
<ul>
<li>T-dist is a probability dist like a normal-dist but bigger tails
<ul>
<li>infinite degree of freedom result in T-dist = normal-dist</li>
</ul></li>
<li>smaller degree of freedoms imply bigger tails</li>
<li>Can be useful to model returns with fat fails</li>
</ul>
<p>Null H: There is no linear relationship between independent variable and output <span class="math inline">\(\beta = 0\)</span><br />
Alt H: There is a linear relationship between independent variable and output <span class="math inline">\(\beta \neq 0\)</span></p>
<p><strong>We do a T-test for EACH coefficient.</strong><br />
What happens when only some coefficient are significant and others arent.<br />
ANSWER: Typically, we throw out nonsignificant (high p-value) coefficients to sacrifice some bias to reduce variance.<br />
Remember high variance leads to overfit.</p>
<section id="degree-of-freedom" class="level4" data-number="2.4.1.1">
<h4 data-number="2.4.1.1"><span class="header-section-number">2.4.1.1</span> degree of freedom</h4>
</section>
</section>
<section id="validate-multi-linear-regression-model" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2"><span class="header-section-number">2.4.2</span> Validate multi-linear regression model</h3>
<section id="f-test" class="level4" data-number="2.4.2.1">
<h4 data-number="2.4.2.1"><span class="header-section-number">2.4.2.1</span> F-test</h4>
<p>Null H: None of the independent variable have a linear relationship with output <span class="math inline">\(\forall n, \beta_n = 0\)</span><br />
Alt H: At least one of the independent variable have a linear relationship with output<span class="math inline">\(\exists n, \beta_n \neq 0\)</span></p>
<p>Variance WITHIN groups vs Variance BETWEEN groups</p>
<p>Example:</p>
<p>High WITHIN group Variance</p>
<ul>
<li>Height: 10, 9, 12</li>
<li>Weight: 92, 95, 93</li>
<li>Age: 20, 22, 21</li>
</ul>
<p>High BETWEEN group Variance</p>
<ul>
<li>Height: 15, 30</li>
</ul>
</section>
</section>
</section>
<section id="model-fit-loss-function" class="level2" data-number="2.5">
<h2 data-number="2.5"><span class="header-section-number">2.5</span> Model fit ( Loss Function )</h2>
<section id="mse" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1"><span class="header-section-number">2.5.1</span> MSE</h3>
<ul>
<li>MSE(Mean Squared Error) : used to check how well our regression model fits
<ul>
<li>Add the squared distance from point to regression, then divide by count of datapoints</li>
</ul></li>
<li>Notice <span class="math inline">\(MSE = \frac{1}{n} RSS\)</span></li>
</ul>
<p>Goal is to minimize MSE of test dataset, not training dataset</p>
<section id="standard-error-se" class="level4" data-number="2.5.1.1">
<h4 data-number="2.5.1.1"><span class="header-section-number">2.5.1.1</span> Standard Error SE</h4>
<ul>
<li>how far the sample {mean,weights,residuals} are from the reality or population {mean,weights,residuals}</li>
</ul>
</section>
<section id="rse-serss" class="level4" data-number="2.5.1.2">
<h4 data-number="2.5.1.2"><span class="header-section-number">2.5.1.2</span> RSE = SE(RSS)</h4>
<p>Standard Error of RSS is RSE</p>
</section>
</section>
<section id="r2" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2"><span class="header-section-number">2.5.2</span> R^2</h3>
<p><span class="math inline">\(R^2\)</span> is a number in [0,1] and related to Variance(Scatter or Clumped)<br />
<span class="math inline">\(R^2\)</span> measure how scattered or clumped the data WRT our regression line aka model.</p>
<ul>
<li>Close to 1 means every datapoint is on our regression line</li>
<li>Close to 0 means the datapoint are scattered but broadly follow trend with our regression line.</li>
</ul>
<p>Optional: Drop coefficients aka Independent Random variables that do not contribute well in <span class="math inline">\(R^2\)</span> <strong>despite having low p-value</strong></p>
<p>Example:
Age variable gives <span class="math inline">\(R^2\)</span> 0.7 with p-value: 0.04
Adding a height variable gives <span class="math inline">\(R^2\)</span> 0.71 with p-value 0.005<br />
We can safely drop height variable</p>
<p>Cons:</p>
<ul>
<li><code>R^2</code> increases as you add more parameters
<ul>
<li>Solution: used <code>Adj-R^2</code></li>
</ul></li>
</ul>
</section>
<section id="cor" class="level3" data-number="2.5.3">
<h3 data-number="2.5.3"><span class="header-section-number">2.5.3</span> Cor</h3>
<p><span class="math display">\[R^2 = Cor(Y,\hat{Y})^2 \text{ for multiple lin reg}\]</span><br />
Linear fit models aim to <span class="math inline">\(max(Cor(Y,\hat{Y}))\)</span></p>
</section>
</section>
<section id="prediction" class="level2" data-number="2.6">
<h2 data-number="2.6"><span class="header-section-number">2.6</span> Prediction</h2>
<p>Prediction interval</p>
</section>
</section>
<section id="chapter-4-classification" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Chapter 4 Classification</h1>
<p>Why can’t we just do one-hot encoding with linear regression?<br />
We Can but only for binary outcomes</p>
<p>If we do it for more than binary outcomes, we create an equidistant ordering which may not reflect reality.</p>
</section>
<section id="chapter-5-resampling" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Chapter 5 Resampling</h1>
<p>Remember statistics is about how using our subset/sample to understand the population.</p>
<p>Resampling is about repeatedly taking different subsets or samples.</p>
<p>Two common resampling method: Cross-validation, bootstrap</p>
</section>

        </div>
        <div id="footer">
            <div class="flex-container" style="display:flex; justify-content: space-between;">
                <div>
                    Site proudly generated by
                    <a href="http://jaspervdj.be/hakyll">Hakyll</a>
                </div>
                <div class="pagehitscounter"> 
                    <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fuserjy.github.io&count_bg=%231FDBD9&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=true" />
                </div>
                <div xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://lambdaJasonYang.github.io/">Jason's Notes</a> by <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://lambdaJasonYang.github.io/">Jason Yang</a> is licensed under <a href="http://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-ND 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nd.svg?ref=chooser-v1"></a></div>
  
            </div>
        </div>
        
    </body>
    <footer>
        <!-- CODE TAB START -->
        <script>
                    //Structure:
                    // Codeblock < Group/Grouplabel/subgrp < datagroupSet < allblocks

            const AllBlocksPre = document.querySelectorAll("[data-group]");
            const AllBlocks = [...AllBlocksPre]; //gets all codeblocks w/ and w/o group label
            const getUniqueSet = (TargetSet,dataAttr) => {
                //gets the set of attributes of an array of codeblocks aka TargetSet
                const temp = TargetSet.map((e) => (e.getAttribute(dataAttr))); 
                const temp2 = temp.filter((a)=>a); //remove nulls
                return [...new Set(temp2)];
            } 
            const datagroupSet = getUniqueSet(AllBlocks,"data-group") //remove nulls

            const getCodeBlocks = (datagroup) => {
                //return list of glabels CodeBlocks associated to a single group 
                return AllBlocks.filter((dataglabelBlock)=>(dataglabelBlock.getAttribute("data-group") === datagroup));
            }

            const showBlocks = (dataglabeltxt,datagroupCodeBlocks) => {
                const selectedglabelGroup = datagroupCodeBlocks.filter((SingleBlock)=>(SingleBlock.getAttribute("data-glabel") === dataglabeltxt))
                const NONselectedglabelGroup = datagroupCodeBlocks.filter((SingleBlock)=>(SingleBlock.getAttribute("data-glabel") !== dataglabeltxt))
                selectedglabelGroup.map((SingleBlock) => (SingleBlock.style.display="block"));
                (NONselectedglabelGroup || []).map((SingleBlock) => (SingleBlock.style.display="none"));
            }
            const mkBtn = (dataglabeltxt,datagroupCodeBlocks,showfunc) => {
                const newbutton = document.createElement("input");
                newbutton.type = "radio";
                // newbutton.textContent = dataglabeltxt;
                newbutton.addEventListener('click', ()=>{
                    // console.log(datagroupCodeBlocks)
                    showfunc(dataglabeltxt,datagroupCodeBlocks);
                });
                return newbutton;
            }
            const showAll = (datagroup) => {
                //make all codeblocks visible
            datagroup.map((e)=>(e.style.display="block"));
            }

            const buildCodeTab = (datagroupCodeBlocks,datagroup) => {
                const leaderCodeBlockDiv = datagroupCodeBlocks[0]; //get the leader codeblock of a group of codeblock
                const setglabelstxt = getUniqueSet(datagroupCodeBlocks,"data-glabel"); 
                setglabelstxt.map((singleglabeltxt)=>{
                    
                    const btn = mkBtn(singleglabeltxt,datagroupCodeBlocks,showBlocks);
                    btn.name = datagroup;
                    btn.id = datagroup+singleglabeltxt;
                    const radiolabelx = document.createElement("label");
                    radiolabelx.setAttribute("for",datagroup+singleglabeltxt);
                    radiolabelx.innerText = singleglabeltxt;
        
                    // leaderCodeBlockDiv.insertAdjacentElement("beforebegin",radiolabelx);
                    // radiolabelx.appendChild(btn);
                    const radioclass = document.createElement("div");
                    radioclass.className = "radioclass";
                    radioclass.appendChild(btn);
                    radioclass.appendChild(radiolabelx)
                    leaderCodeBlockDiv.insertAdjacentElement("beforebegin",radioclass);
                    // leaderCodeBlockDiv.prepend(btn);
                    
                    
                })
             
                // leaderCodeBlockDiv.append(btnlist);
                
                const btnShowAll = document.createElement("input");
                btnShowAll.type = "radio";
                btnShowAll.addEventListener('click',(e)=>(showAll(datagroupCodeBlocks)));

                btnShowAll.name = datagroup;
                btnShowAll.id = datagroup+"All";
                const radiolabel = document.createElement("label");
                radiolabel.setAttribute("for",datagroup+"All");
                radiolabel.innerText = "All";

                const radioclass = document.createElement("div");
                radioclass.className = "radioclass";
                radioclass.appendChild(btnShowAll);
                radioclass.appendChild(radiolabel)
                leaderCodeBlockDiv.insertAdjacentElement('beforebegin',radioclass);
                //make showAllbutton END
            }

            //below code is performing actual behavior, the above code are just functions
            datagroupSet.map((datagroup) => {
                
                const groupOfCodeblocks = getCodeBlocks(datagroup);
                buildCodeTab(groupOfCodeblocks,datagroup);
                const firsttab = groupOfCodeblocks[0];
                showBlocks(firsttab.getAttribute("data-glabel"),groupOfCodeblocks);
       
            })
        </script>
        <!-- CODE TAB END ---->

        <!-- MATH JAX START -------------------------------------- -->
        <script id="MathJax-script" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-chtml.min.js">
        </script>
        <!-- MATH JAX END ----------------------------------------- -->
        <!-- MERMAID START -------------------------------------- -->
        <script type="module"> 
            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/+esm'
        </script>
        <!-- <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js" async></script> -->
        <!-- MERMAID END -------------------------------------- -->
        <!-- RAILROAD START -------------------------------------- -->
        <script type="module">
            import rr,* as rrClass from "/lib/railroad/railroad.js";
            Object.assign(window,rr)
            window.rrOptions = rrClass.Options;
            document.addEventListener('DOMContentLoaded',()=>{ReplaceDivWithSvg()},false)
            const ReplaceDivWithSvg = () =>  {
                for (const railroadelem of document.getElementsByClassName("rroad") ){
                railroadelem.innerHTML = eval(railroadelem.innerText.trim()+".toString()")
                }
            }
        </script>
        

        <link rel="stylesheet" href="../lib/railroad/railroad-diagrams.css">
        <!-- RAILROAD END ----------------------------------------- -->
    </footer>
</html>
